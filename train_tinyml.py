from pathlib import Path

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

DATA_PATH = Path("dataset_th.csv")

def main():
    df = pd.read_csv(DATA_PATH)
    X = df[["temp", "hum"]].values
    y = df["label"].values   # 0,1,2

    classes = np.unique(y)
    n_classes = len(classes)
    print("Unique labels in data:", classes)

    if n_classes < 2:
        print("Cần ít nhất 2 lớp để train. Hãy thu thêm dữ liệu với điều kiện môi trường khác nhau.")
        return

    # Chuẩn hóa dữ liệu
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Train / test split
    if n_classes >= 2:
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42,
            stratify=y if n_classes > 1 else None
        )
    else:
        X_train, X_test, y_train, y_test = X_scaled, X_scaled, y, y

    clf = LogisticRegression(
        multi_class="auto",
        max_iter=1000
    )
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    print("Accuracy:", acc)
    print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))
    print("Report:\n", classification_report(y_test, y_pred))

    # Trích weights, bias và tham số chuẩn hóa
    W = clf.coef_        # shape (n_classes, 2)
    b = clf.intercept_   # shape (n_classes,)
    mean = scaler.mean_  # shape (2,)
    scale = scaler.scale_  # shape (2,)

    print("\nClasses order in model:", clf.classes_)

    out_path = Path("tinyml_model.h")
    with out_path.open("w", encoding="utf-8") as f:
        f.write("#pragma once\n")
        f.write("#include <Arduino.h>\n\n")
        f.write("// Automatically generated by train_tinyml.py\n")
        f.write("static const int TINYML_N_CLASSES = %d;\n" % n_classes)
        f.write("static const int TINYML_N_FEATURES = 2;\n\n")

        # Lưu mapping class labels (vd [0,1,2])
        f.write("static const int TINYML_CLASSES[%d] = { " % n_classes)
        f.write(", ".join(str(int(c)) for c in classes))
        f.write(" };\n\n")

        f.write("static const float TINYML_MEAN[2] = { %.6ff, %.6ff };\n" %
                (mean[0], mean[1]))
        f.write("static const float TINYML_SCALE[2] = { %.6ff, %.6ff };\n\n" %
                (scale[0], scale[1]))

        f.write("static const float TINYML_WEIGHTS[%d][2] = {\n" % n_classes)
        for i in range(n_classes):
            f.write("  { %.6ff, %.6ff }%s\n" %
                    (W[i, 0], W[i, 1], "," if i < n_classes - 1 else ""))
        f.write("};\n\n")

        f.write("static const float TINYML_BIASES[%d] = { " % n_classes)
        f.write(", ".join("%.6ff" % bi for bi in b))
        f.write(" };\n\n")

        f.write("static inline int tinyml_predict(float temp, float hum) {\n")
        f.write("  // Chuẩn hóa giống trên PC\n")
        f.write("  float x0 = (temp - TINYML_MEAN[0]) / TINYML_SCALE[0];\n")
        f.write("  float x1 = (hum  - TINYML_MEAN[1]) / TINYML_SCALE[1];\n")
        f.write("  float best_logit = -1e9f;\n")
        f.write("  int best_idx = 0;\n")
        f.write("  for (int i = 0; i < TINYML_N_CLASSES; ++i) {\n")
        f.write("    float z = TINYML_WEIGHTS[i][0] * x0 + "
                "TINYML_WEIGHTS[i][1] * x1 + TINYML_BIASES[i];\n")
        f.write("    if (z > best_logit) { best_logit = z; best_idx = i; }\n")
        f.write("  }\n")
        f.write("  // Trả về nhãn gốc (0,1,2,...)\n")
        f.write("  return TINYML_CLASSES[best_idx];\n")
        f.write("}\n")

    print("\nWritten header to", out_path.resolve())

if __name__ == "__main__":
    main()
